{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1.2: Producer 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "Success publishing message. Data: {'latitude': -37.7126, 'longitude': 141.6103, 'confidence': 76.0, 'surface_temperature_celcius': 50.0, 'created_time': '04:35:37', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.6248, 'longitude': 142.2042, 'confidence': 71.0, 'surface_temperature_celcius': 46.0, 'created_time': '14:58:08', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.9175, 'longitude': 142.6639, 'confidence': 77.0, 'surface_temperature_celcius': 50.0, 'created_time': '22:08:19', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -37.34, 'longitude': 149.3668, 'confidence': 67.0, 'surface_temperature_celcius': 74.0, 'created_time': '09:06:35', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -37.8167, 'longitude': 142.1718, 'confidence': 86.0, 'surface_temperature_celcius': 61.0, 'created_time': '03:41:47', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.6288, 'longitude': 144.8682, 'confidence': 72.0, 'surface_temperature_celcius': 47.0, 'created_time': '20:40:39', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.0895, 'longitude': 141.7446, 'confidence': 74.0, 'surface_temperature_celcius': 48.0, 'created_time': '12:54:24', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.102, 'longitude': 146.2785, 'confidence': 80.0, 'surface_temperature_celcius': 53.0, 'created_time': '21:20:43', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -37.332, 'longitude': 143.375, 'confidence': 64.0, 'surface_temperature_celcius': 46.0, 'created_time': '06:10:53', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -37.69, 'longitude': 143.605, 'confidence': 97.0, 'surface_temperature_celcius': 80.0, 'created_time': '21:15:43', 'producer_identifier': 'producer_2'}\n",
      "Success publishing message. Data: {'latitude': -36.2111, 'longitude': 141.505, 'confidence': 68.0, 'surface_temperature_celcius': 44.0, 'created_time': '18:47:42', 'producer_identifier': 'producer_2'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m data_doc \u001b[39m=\u001b[39m add_additional_data(random_data_doc)\n\u001b[1;32m     86\u001b[0m publish_message(producer, topic_name, data_doc)  \u001b[39m#publish chosen data document\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m sleep(publish_interval)  \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import time\n",
    "import json\n",
    "\n",
    "\n",
    "ip_address = \"10.192.68.151\" \n",
    "\n",
    "topic_name = 'climate_hotspot'  #use the same topic for all producers\n",
    "producer_identifier = \"producer_2\"\n",
    "\n",
    "\n",
    "def prepare_streaming_data():\n",
    "        \n",
    "    #read csv file and extract rows\n",
    "    hotspot_aqua_csv = pd.read_csv(\"hotspot_AQUA_streaming.csv\").iterrows()\n",
    "\n",
    "    hotspot_aqua_data = []\n",
    "\n",
    "    #get all streaming data rows as dictionaries (json) and store them\n",
    "    for id, data_row in hotspot_aqua_csv:\n",
    "        row_dict = data_row.to_dict()\n",
    "        hotspot_aqua_data.append(row_dict)\n",
    "\n",
    "    return hotspot_aqua_data\n",
    "\n",
    "#add additional attributes to each data document\n",
    "def add_additional_data(data_document):\n",
    "\n",
    "    #generate random time\n",
    "    hour = random.randint(0, 23)\n",
    "    minutes = random.randint(0, 59)\n",
    "    seconds = random.randint(0, 59)\n",
    "    random_time = time(hour, minutes, seconds)\n",
    "\n",
    "    #add random time and producer identifier label\n",
    "    data_document[\"created_time\"] = random_time.strftime(\"%H:%M:%S\")    #convert to string to make it json serialisable\n",
    "    data_document[\"producer_identifier\"] = producer_identifier\n",
    "\n",
    "    return data_document\n",
    "\n",
    "\n",
    "def publish_message(producer_instance, kafka_topic, data):\n",
    "    try:\n",
    "        producer_instance.send(kafka_topic, value=data)  #send the message to the specified topic\n",
    "        producer_instance.flush()  #make sure that the message is actually sent to Kafka before moving on\n",
    "\n",
    "        print('Success publishing message. Data: ' + str(data))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Error! Message could not be published')\n",
    "        print(str(e))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        #create producer at given address port\n",
    "        _producer = KafkaProducer(bootstrap_servers=[f'{ip_address}:9092'],\n",
    "                                  value_serializer=lambda x: json.dumps(x).encode('ascii'),  #encode as bytes because Kafka messages are sent as byte arrays\n",
    "                                  api_version=(0, 10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Could not create producer. Error connecting to Kafka.')\n",
    "        print(str(e))\n",
    "\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    streaming_climate_data = prepare_streaming_data()  #get all streaming data as dictionary objects (like json)\n",
    "    print('Publishing records..')\n",
    "    producer = connect_kafka_producer()\n",
    "    \n",
    "    while True:\n",
    "        #publish data in random intervals (1 to 20 seconds)\n",
    "        publish_interval = random.randint(1, 20)  \n",
    "\n",
    "        #choose document randomly\n",
    "        random_doc_id = random.randint(0, len(streaming_climate_data)-1) \n",
    "        random_data_doc = streaming_climate_data[random_doc_id]\n",
    "\n",
    "        data_doc = add_additional_data(random_data_doc)\n",
    "        publish_message(producer, topic_name, data_doc)  #publish chosen data document\n",
    "\n",
    "        sleep(publish_interval)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
