{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Getting the latest date from the climate collection in mongodb:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "#setup mongo client\n",
    "ip_address = '10.192.68.151'\n",
    "mongo_client = MongoClient(ip_address, 27017)\n",
    "\n",
    "#create or get database \n",
    "db = mongo_client[\"fit3182_assignment_db\"]\n",
    "\n",
    "#create collection for climate data\n",
    "climate_col = db.climates_historic\n",
    "\n",
    "#create pipeline to get all dates from climate collection\n",
    "pipeline_stages = [{\"$project\": {\"date\": 1}}] \n",
    "latest_climate_doc = climate_col.aggregate(pipeline_stages)   \n",
    "\n",
    "dates = []  #list of all dates from climate collection\n",
    "\n",
    "for doc in latest_climate_doc:\n",
    "    date_object = datetime.strptime(doc[\"date\"], \"%d/%m/%Y\")  #convert into datetime object so it can be sorted\n",
    "    dates.append(date_object)\n",
    "  \n",
    "dates.sort(reverse=True) #sort dates in descending order\n",
    "latest_date = dates[0].date()\n",
    "\n",
    "print (latest_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1.1: Producer 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "Success publishing message. Data: {'latitude': -36.6851, 'longitude': 141.6125, 'air_temperature_celcius': 17, 'relative_humidity': 59.0, 'windspeed_knots': 9.4, 'max_wind_speed': 15.0, 'precipitation ': ' 0.75G', 'GHI_w/m2': 135, 'date': '2024-01-02', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.461, 'longitude': 148.109, 'air_temperature_celcius': 14, 'relative_humidity': 50.7, 'windspeed_knots': 8.6, 'max_wind_speed': 13.0, 'precipitation ': ' 0.12G', 'GHI_w/m2': 119, 'date': '2024-01-03', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.634, 'longitude': 149.237, 'air_temperature_celcius': 16, 'relative_humidity': 48.4, 'windspeed_knots': 8.1, 'max_wind_speed': 15.9, 'precipitation ': ' 0.00G', 'GHI_w/m2': 139, 'date': '2024-01-04', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -38.495, 'longitude': 146.944, 'air_temperature_celcius': 8, 'relative_humidity': 44.6, 'windspeed_knots': 3.9, 'max_wind_speed': 8.0, 'precipitation ': ' 0.39G', 'GHI_w/m2': 72, 'date': '2024-01-05', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -35.364, 'longitude': 141.063, 'air_temperature_celcius': 15, 'relative_humidity': 51.9, 'windspeed_knots': 6.6, 'max_wind_speed': 12.0, 'precipitation ': ' 0.01G', 'GHI_w/m2': 127, 'date': '2024-01-06', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.461, 'longitude': 148.109, 'air_temperature_celcius': 14, 'relative_humidity': 50.7, 'windspeed_knots': 8.6, 'max_wind_speed': 13.0, 'precipitation ': ' 0.12G', 'GHI_w/m2': 119, 'date': '2024-01-07', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -36.939, 'longitude': 143.28, 'air_temperature_celcius': 20, 'relative_humidity': 67.4, 'windspeed_knots': 8.5, 'max_wind_speed': 14.0, 'precipitation ': ' 0.63G', 'GHI_w/m2': 147, 'date': '2024-01-08', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.189, 'longitude': 146.791, 'air_temperature_celcius': 21, 'relative_humidity': 61.1, 'windspeed_knots': 6.6, 'max_wind_speed': 11.1, 'precipitation ': ' 0.00I', 'GHI_w/m2': 163, 'date': '2024-01-09', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.336, 'longitude': 148.073, 'air_temperature_celcius': 7, 'relative_humidity': 40.5, 'windspeed_knots': 8.1, 'max_wind_speed': 15.0, 'precipitation ': ' 0.12G', 'GHI_w/m2': 65, 'date': '2024-01-10', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -35.953, 'longitude': 141.078, 'air_temperature_celcius': 12, 'relative_humidity': 47.2, 'windspeed_knots': 8.8, 'max_wind_speed': 15.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 105, 'date': '2024-01-11', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -35.2881, 'longitude': 142.5679, 'air_temperature_celcius': 17, 'relative_humidity': 38.7, 'windspeed_knots': 16.8, 'max_wind_speed': 22.9, 'precipitation ': ' 0.00I', 'GHI_w/m2': 159, 'date': '2024-01-12', 'producer_identifier': 'producer_1'}\n",
      "Success publishing message. Data: {'latitude': -37.367, 'longitude': 148.04, 'air_temperature_celcius': 12, 'relative_humidity': 47.6, 'windspeed_knots': 9.1, 'max_wind_speed': 13.0, 'precipitation ': ' 0.12G', 'GHI_w/m2': 105, 'date': '2024-01-13', 'producer_identifier': 'producer_1'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m data_doc \u001b[39m=\u001b[39m add_additional_data(random_data_doc)\n\u001b[1;32m     82\u001b[0m publish_message(producer, topic_name, data_doc)  \u001b[39m#publish chosen data document\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m sleep(\u001b[39m10\u001b[39;49m)  \u001b[39m#publish data every 10 seconds\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import timedelta as td\n",
    "import json\n",
    "\n",
    "\n",
    "ip_address = \"10.192.68.151\" \n",
    "\n",
    "new_date = latest_date\n",
    "topic_name = 'climate_hotspot'  #use the same topic for all producers\n",
    "producer_identifier = \"producer_1\"\n",
    "\n",
    "\n",
    "def prepare_streaming_data():\n",
    "        \n",
    "    #read csv file and extract rows\n",
    "    streaming_data_csv = pd.read_csv(\"climate_streaming.csv\").iterrows()\n",
    "\n",
    "    streaming_climate_data = []\n",
    "\n",
    "    #get all streaming data rows as dictionaries (json) and store them\n",
    "    for id, data_row in streaming_data_csv:\n",
    "        row_dict = data_row.to_dict()\n",
    "        streaming_climate_data.append(row_dict)\n",
    "\n",
    "    return streaming_climate_data\n",
    "\n",
    "#add additional attributes to each data document\n",
    "def add_additional_data(data_document):\n",
    "    global new_date  #ensure date is incremented sequentially by using global variable\n",
    "\n",
    "    new_date = new_date + td(days=1)  #increment date by 1 \n",
    "\n",
    "    #add created date and producer identifier label\n",
    "    data_document[\"date\"] = new_date.strftime(\"%Y-%m-%d\")    #convert to string to make it json serialisable\n",
    "    data_document[\"producer_identifier\"] = producer_identifier\n",
    "\n",
    "    return data_document\n",
    "\n",
    "\n",
    "def publish_message(producer_instance, kafka_topic, data):\n",
    "    try:\n",
    "        producer_instance.send(kafka_topic, value=data)  #send the message to the specified topic\n",
    "        producer_instance.flush()  #make sure that the message is actually sent to Kafka before moving on\n",
    "\n",
    "        print('Success publishing message. Data: ' + str(data))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Error! Message could not be published')\n",
    "        print(str(e))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        #create producer at given address port\n",
    "        _producer = KafkaProducer(bootstrap_servers=[f'{ip_address}:9092'],\n",
    "                                  value_serializer=lambda x: json.dumps(x).encode('ascii'),  #encode as bytes because Kafka messages are sent as byte arrays\n",
    "                                  api_version=(0, 10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Could not create producer. Error connecting to Kafka.')\n",
    "        print(str(e))\n",
    "\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    streaming_climate_data = prepare_streaming_data()  #get all streaming data as dictionary objects (like json)\n",
    "    print('Publishing records..')\n",
    "    producer = connect_kafka_producer()\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        #choose document randomly\n",
    "        random_doc_id = random.randint(0, len(streaming_climate_data)-1) \n",
    "        random_data_doc = streaming_climate_data[random_doc_id]\n",
    "\n",
    "        data_doc = add_additional_data(random_data_doc)\n",
    "        publish_message(producer, topic_name, data_doc)  #publish chosen data document\n",
    "\n",
    "        sleep(10)  #publish data every 10 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
